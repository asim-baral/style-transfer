{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FieA57yqoRFM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bu5Piu2ptIH",
        "outputId": "6df15e7f-8918-4235-e186-55f0ea12c22d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class vggFeatureClass(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(vggFeatureClass, self).__init__()\n",
        "\n",
        "    model = models.vgg16(pretrained=True)\n",
        "    self.modelLayers = model.features[:25].to(device)\n",
        "\n",
        "    for param in self.modelLayers.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    feature = []\n",
        "    for ind, layer in enumerate(self.modelLayers):\n",
        "      x = layer(x)\n",
        "\n",
        "      if ind in {0,5,10,17,24}:\n",
        "        feature.append(x)\n",
        "\n",
        "    return feature"
      ],
      "metadata": {
        "id": "lZ5c9dBTqw4F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(334),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "yAIrRwsLpCRi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('image.png')\n",
        "image = transform(image)\n",
        "image = image.to(device)\n",
        "\n",
        "style = Image.open('style.jpg')\n",
        "style = transform(style)\n",
        "style = style.to(device)\n"
      ],
      "metadata": {
        "id": "4M3I_7oeoopP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generatedImg = image.clone().detach().to(device).requires_grad_(True)"
      ],
      "metadata": {
        "id": "0eKUt3zVuvNc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_times = 4000\n",
        "alpha = 1\n",
        "beta = 0.001\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "bF503HC8uR8q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.Adam([generatedImg], lr=learning_rate)\n",
        "vggFeature = vggFeatureClass().to(device)"
      ],
      "metadata": {
        "id": "GoFgBrnLyghT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(no_times+1):\n",
        "  imageFeature = vggFeature(image)\n",
        "  styleFeature = vggFeature(style)\n",
        "  generatedImgFeature = vggFeature(generatedImg)\n",
        "\n",
        "  loss = 0\n",
        "  for i in range(len(imageFeature)):\n",
        "    shape = imageFeature[i].shape\n",
        "    imageFeature_reshaped = imageFeature[i].reshape(shape[0], -1)\n",
        "    styleFeature_reshaped = styleFeature[i].reshape(shape[0], -1)\n",
        "    generatedImgFeature_reshaped = generatedImgFeature[i].reshape(shape[0], -1)\n",
        "\n",
        "    orgLoss = torch.mean((imageFeature_reshaped - generatedImgFeature_reshaped)**2)\n",
        "\n",
        "    gramS = styleFeature_reshaped @ styleFeature_reshaped.t()\n",
        "    gramG = generatedImgFeature_reshaped @ generatedImgFeature_reshaped.t()\n",
        "    styleLoss = torch.mean((gramS - gramG)**2)\n",
        "\n",
        "    loss += alpha*orgLoss + beta*styleLoss\n",
        "\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  optim.zero_grad()\n",
        "  avgLoss = loss.item()\n",
        "  if n%50 == 0:\n",
        "    print(\"In \",n, \" Loss: \",avgLoss)\n",
        "    img_pil = transforms.ToPILImage()(generatedImg.clamp(0, 1))\n",
        "    if n%1000 == 0:\n",
        "      img_pil.save(f\"generatedImg{n}.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtpyyAyXqQB0",
        "outputId": "39da696c-765f-4e26-a782-044e8e75dcce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In  0  Loss:  146318.140625\n",
            "In  50  Loss:  43227.2734375\n",
            "In  100  Loss:  23550.025390625\n",
            "In  150  Loss:  17028.58984375\n",
            "In  200  Loss:  13578.1787109375\n",
            "In  250  Loss:  11376.1884765625\n",
            "In  300  Loss:  9829.9892578125\n",
            "In  350  Loss:  8675.271484375\n",
            "In  400  Loss:  7770.05810546875\n",
            "In  450  Loss:  7034.27490234375\n",
            "In  500  Loss:  6418.9990234375\n",
            "In  550  Loss:  5891.8232421875\n",
            "In  600  Loss:  5434.2236328125\n",
            "In  650  Loss:  5032.1943359375\n",
            "In  700  Loss:  4675.77490234375\n",
            "In  750  Loss:  4357.7099609375\n",
            "In  800  Loss:  4072.177734375\n",
            "In  850  Loss:  3813.872314453125\n",
            "In  900  Loss:  3579.263671875\n",
            "In  950  Loss:  3365.90234375\n",
            "In  1000  Loss:  3171.191650390625\n",
            "In  1050  Loss:  2992.74169921875\n",
            "In  1100  Loss:  2828.75\n",
            "In  1150  Loss:  2677.664306640625\n",
            "In  1200  Loss:  2538.179931640625\n",
            "In  1250  Loss:  2409.03662109375\n",
            "In  1300  Loss:  2288.927734375\n",
            "In  1350  Loss:  2176.66650390625\n",
            "In  1400  Loss:  2071.77392578125\n",
            "In  1450  Loss:  1973.8218994140625\n",
            "In  1500  Loss:  1882.3409423828125\n",
            "In  1550  Loss:  1796.72412109375\n",
            "In  1600  Loss:  1716.5538330078125\n",
            "In  1650  Loss:  1641.6702880859375\n",
            "In  1700  Loss:  1571.7696533203125\n",
            "In  1750  Loss:  1506.659912109375\n",
            "In  1800  Loss:  1445.99951171875\n",
            "In  1850  Loss:  1389.508056640625\n",
            "In  1900  Loss:  1337.0732421875\n",
            "In  1950  Loss:  1288.5670166015625\n",
            "In  2000  Loss:  1243.572021484375\n",
            "In  2050  Loss:  1201.9002685546875\n",
            "In  2100  Loss:  1163.3104248046875\n",
            "In  2150  Loss:  1127.5555419921875\n",
            "In  2200  Loss:  1094.4925537109375\n",
            "In  2250  Loss:  1063.8837890625\n",
            "In  2300  Loss:  1035.3892822265625\n",
            "In  2350  Loss:  1008.910888671875\n",
            "In  2400  Loss:  984.2229614257812\n",
            "In  2450  Loss:  961.0719604492188\n",
            "In  2500  Loss:  939.417236328125\n",
            "In  2550  Loss:  919.150390625\n",
            "In  2600  Loss:  900.1668701171875\n",
            "In  2650  Loss:  882.248779296875\n",
            "In  2700  Loss:  865.2218627929688\n",
            "In  2750  Loss:  849.039306640625\n",
            "In  2800  Loss:  833.64599609375\n",
            "In  2850  Loss:  818.9547729492188\n",
            "In  2900  Loss:  804.89453125\n",
            "In  2950  Loss:  791.4405517578125\n",
            "In  3000  Loss:  778.5281982421875\n",
            "In  3050  Loss:  766.0684814453125\n",
            "In  3100  Loss:  754.0901489257812\n",
            "In  3150  Loss:  742.567138671875\n",
            "In  3200  Loss:  731.451416015625\n",
            "In  3250  Loss:  720.8560180664062\n",
            "In  3300  Loss:  710.5755615234375\n",
            "In  3350  Loss:  700.4451904296875\n",
            "In  3400  Loss:  690.7575073242188\n",
            "In  3450  Loss:  681.6480102539062\n",
            "In  3500  Loss:  672.911376953125\n",
            "In  3550  Loss:  663.813720703125\n",
            "In  3600  Loss:  655.7094116210938\n",
            "In  3650  Loss:  647.9215087890625\n",
            "In  3700  Loss:  639.6778564453125\n",
            "In  3750  Loss:  632.593505859375\n",
            "In  3800  Loss:  625.0856323242188\n",
            "In  3850  Loss:  618.7777099609375\n",
            "In  3900  Loss:  611.5953979492188\n",
            "In  3950  Loss:  604.6845703125\n",
            "In  4000  Loss:  598.8255615234375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFdofgH2ETA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}